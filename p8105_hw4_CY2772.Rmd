---
title: "p8105_hw4_CY2772"
author: "Chenhui Yan"
date: "2024-11-14"
output: github_document
---
```{r}
library(tidyverse)
library(broom)
library(purrr)
library(knitr)
library(ggplot2)
```

# Problem 1: Birthday problem
```{r}
# Create the simulation function
simulate_birthday = function(n) {
  birthdays <- sample(1:365, size = n, replace = TRUE)
  any(duplicated(birthdays))
}
```
```{r}
# Run the simulation for each group size
set.seed(123)  # For reproducibility

group_sizes = 2:50
num_simulations = 10000

probabilities = sapply(group_sizes, function(n) {
  results = replicate(num_simulations, simulate_birthday(n))
  mean(results)
})
```


```{r}
# Plot the probabilities

plot_data = data.frame(
  group_size = group_sizes,
  probability = probabilities
)

ggplot(plot_data, aes(x = group_size, y = probability)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(
    title = "Probability of At Least Two People Sharing a Birthday",
    x = "Group Size",
    y = "Probability"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))

```

The plot shows a sigmoid-like curve, starting very low for small groups and then rapidly increasing around group sizes of 20-30, and then leveling off near 1 (100%) for group sizes approaching 50.

# Problem 2:
```{r}
#Simulating the Data and Performing the Tests
set.seed(123)  # for reproducibility

n = 30
sigma = 5
mu_values = 1:6
num_simulations = 5000

results = data.frame()

for (mu in mu_values) {
  for (i in 1:num_simulations) {
    # Generate a dataset from N(mu, sigma^2)
    x = rnorm(n, mean = mu, sd = sigma)
    
    # Perform a one-sample t-test
    test_result = t.test(x, mu = 0)
    tidy_result = tidy(test_result)
    
    # Store the estimated mean and p-value
    results = rbind(results, data.frame(
      true_mu = mu,
      estimate = mean(x),
      p_value = tidy_result$p.value
    ))
  }
}

```

```{r}
#Calculating Power and Summarizing Results
summary_results = results %>%
  group_by(true_mu) %>%
  summarize(
    power = mean(p_value < 0.05),
    avg_estimate = mean(estimate),
    avg_estimate_rejected = mean(estimate[p_value < 0.05], na.rm = TRUE)
  )
  
summary_results

```

```{r}
#Visualization and Interpretation
#a): Plotting the Power of the Test
ggplot(summary_results, aes(x = true_mu, y = power)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(
    title = "Power of the One-Sample t-Test",
    x = "True Mean (µ)",
    y = "Power (Proportion of Times Null Rejected)"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))

```

When the true mean diverges further from the null hypothesis value of zero, the test's power increases correspondingly. This means that as the effect size grows, the likelihood of correctly rejecting the null hypothesis also rises. 
```{r}
#(b) Plotting the Average Estimates
# Average estimate across all samples
plot_avg_estimate = ggplot(summary_results, aes(x = true_mu, y = avg_estimate)) +
  geom_line(color = "green") +
  geom_point(color = "darkgreen") +
  labs(
    title = "Average Estimated Mean (µ̂) vs True Mean (µ)",
    x = "True Mean (µ)",
    y = "Average Estimated Mean (µ̂)"
  ) +
  theme_minimal()

# Average estimate only where null was rejected
plot_avg_estimate_rejected = ggplot(summary_results, aes(x = true_mu, y = avg_estimate_rejected)) +
  geom_line(color = "purple") +
  geom_point(color = "darkmagenta") +
  labs(
    title = "Average Estimated Mean (µ̂) for Rejected Nulls vs True Mean (µ)",
    x = "True Mean (µ)",
    y = "Average Estimated Mean (µ̂)"
  ) +
  theme_minimal()

plot_avg_estimate
plot_avg_estimate_rejected

```
```{r}
ggplot(summary_results, aes(x = true_mu)) +
  geom_line(aes(y = avg_estimate, color = "All Samples")) +
  geom_point(aes(y = avg_estimate, color = "All Samples")) +
  geom_line(aes(y = avg_estimate_rejected, color = "Rejected Null")) +
  geom_point(aes(y = avg_estimate_rejected, color = "Rejected Null")) +
  scale_color_manual(values = c("All Samples" = "blue", "Rejected Null" = "red")) +
  labs(
    title = "Comparison of Average Estimated Mean (µ̂)",
    x = "True Mean (µ)",
    y = "Average Estimated Mean (µ̂)",
    color = "Sample Type"
  ) +
  theme_minimal()

```
When considering all samples, the average estimated mean $\hat{\mu}$ closely reflects the true mean value. However, if we examine only the samples where the null hypothesis was rejected, the average estimate tends to be higher than the true mean, particularly when the true mean is small. This happens due to selection bias, as only those samples that show larger deviations from the null hypothesis are included in this subset.

# Problem3
## Load and describe the raw data
```{r}
homicides = read_csv("./homicide-data.csv")|>
  janitor::clean_names()
summary(homicides)
```
## create city_state variable and summarise
```{r}
# Create a new 'city_state' variable by combining 'city' and 'state'
homicides = homicides %>% 
  mutate(city_state = paste(city, state, sep = ", "))

# Summarize the total and unsolved homicides by 'city_state'
summ_homicides = homicides %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

# Display the summarized data in a nicely formatted table
summ_homicides %>%  knitr::kable()

```
```{r}
# Use dplyr's filter function to get data for Baltimore, MD
baltimore_data = summ_homicides %>%
  filter(city_state == "Baltimore, MD") %>%
  select(unsolved_homicides, total_homicides)

unsolved_cases = baltimore_data$unsolved_homicides
total_cases = baltimore_data$total_homicides

# Perform the proportion test
baltimore_prop_test = prop.test(
  x = unsolved_cases,
  n = total_cases
)


baltimore_results = baltimore_prop_test %>%
  tidy() %>%
  select(estimate, conf.low, conf.high)

# Display the results
print(baltimore_results)

```
```{r}
# Perform proportion tests for all cities
city_proportions = summ_homicides %>%
  mutate(
    # Apply prop.test to unsolved and total homicides for each city
    prop_test = map2(
      unsolved_homicides,
      total_homicides,
      ~ prop.test(x = .x, n = .y) %>% tidy()
    )
  ) %>%
  unnest(prop_test) %>%
  select(
    city_state,
    estimated_proportion = estimate,
    conf_low = conf.low,
    conf_high = conf.high
  )
# Display the estimated proportions and confidence intervals in a table
city_proportions %>%
  kable(
    col.names = c("City, State", "Estimated Proportion", "CI Lower", "CI Upper"),
    caption = "Proportion of Unsolved Homicides by City",
    digits = 3,
    format = "markdown"
  )
```

```{r}
ggplot(city_proportions, aes(x = reorder(city_state, estimated_proportion), y = estimated_proportion, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion of Unsolved Homicides"
  ) +
  theme_minimal() +
  theme(legend.position = 'none')



```

